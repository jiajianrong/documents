*[译自](https://www.nginx.com/blog/10-tips-for-10x-application-performance/)*



## Linux性能

Linux默认以保守的方式使用系统资源，典型的适应desktop应用负荷。这意味着web应用情形下需要一些调优才能达到最大性能。

下面的优化仅针对Linux作为web服务器，以Nginx为例：


Backlog queue C 如果有链接延迟的情况，可以考虑增加 `net.core.somaxconn`，该值代表在等待Nginx处理时，系统能够缓存connection的最大个数。该值太小的话可能会报错，可以逐渐增大它直到错误消失

File descriptors C 每一个链接Nginx都会使用两个文件描述符。你可能需要增大文件描述符的系统级限制 `sys.fs.file_max` 以及用户级限制 `nofile`

Ephemeral ports C 作为反向代理的Nginx在连接upstream时会创建临时端口。可以增大 `net.ipv4.ip_local_port_range` 来增加端口的可选范围。也可以缩小 `net.ipv4.tcp_fin_timeout` 来减少非活跃端口的timeout时间，进而使该端口被重新利用，



## Web Server性能

下面的建议适用于任何web server，特别是Nginx：


- Access logging C 将多条日志缓存起来一起写入磁盘。对于Nginx，设置 `access_log` 指令的 `buffer=size` 参数，当buffer被填满时日志就会被写入磁盘。 `flush=time` 参数还可以规定在多久之后自动写入

- Buffering C 在内存中缓存相应数据(直到填满buffer)。不能放入内存的响应数据则被写到磁盘上。可以使用 `proxy_buffer_size` 和 `proxy_buffers` 指令设置

- Client keepalives C 对于Nginx，可以增大 `keepalive_requests` 的值，它代表一个client能够通过一个connection发送请求数的最大值，默认是100。也可以增大 `keepalive_timeout` 的值使得connection保持更长时间

- Upstream keepalives C Upstream connections C 作用在应用服务器、数据库服务器等等，也会从keepalive connection设置中受益。对于上游连接，可以增大 `keepalive` 的值，它代表每个worker process中闲置但仍存活状态的connection。这可以使connection被重复利用，避免新建connection。详见[HTTP Keepalive Connections and Web Performance](https://www.nginx.com/blog/http-keepalives-and-web-performance/)

- Limits C 限制client占用的资源可以提高性能和安全性。Nginx中，`limit_conn` 和 `limit_conn_zone` 指令限制了connection对于某类资源的占用上限，`limit_rate` 则是限制了带宽。`limit_req` 和 `limit_req_zone` 指令限制client请求数。 对于upstream服务器，使用 `upstream` 配置块中 `server` 指令的 `max_conns` 参数。这个参数限制了Nginx和upstream服务器之间的connection个数。对应的，`queue` 指令创建一个队列(该队列的最大值)，临时存放超出 `max_conns` 限制之后的请求(在指定时间长度之内)

- Worker processes C 工作进程负责处理请求。Nginx使用事件驱动且独立于平台的机制，分发请求给工作进程。推荐把 `worker_processes` 个数设置成CPU个数。`worker_connections` 的默认值为512，一般可以放心增大该值，可以反复实验测算出最优值

- Socket sharding C 一般来说，只有一个socket listener将新connection分发给所有工作进程。Socket sharding为每一个工作进程都创建一个socket listener，内核将connection委派给socket listener。这样可以减少竞争锁和提升多核系统的性能。请使用 `listen` 指令的 `reuseport` 参数以启用 [socket sharding](https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/)

- Thread pools C 任何进程都有可能被一个很慢的操作所拖累。对于web服务器程序而言，磁盘操作会拖累其他更快的操作，如内存中数据的计算或拷贝。使用线程池执行慢操作，这样可以使主进程始终保持执行快操作。当慢操作执行完毕后，将结果返回给主进程。在Nginx里，两个系统调用 - `read()` 和 `sendfile()` 是交给了[线程池](https://www.nginx.com/blog/thread-pools-boost-performance-9x/)的

